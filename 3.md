# 三、小世界图

现实世界中的许多网络，包括社交网络在内，具有“小世界属性”，即节点之间的平均距离，以最短路径上的边数来衡量，远远小于预期。

在本章中，我介绍了斯坦利·米拉格（Stanley Milgram）的著名的“小世界实验”，这是小世界属性在真正的社交网络中的第一次科学演示。之后我们将考虑 Watts-Strogatz 图，它是一个小世界图的模型。我将复制 Watts 和 Strogatz 所做的实验，并解释它打算展示的东西。

这个过程中，我们将看到两种新的图算法：广度优先搜索（BFS）和 Dijkstra 算法，用于计算图中节点之间的最短路径。

本章的代码在本书仓库的`chap03.ipynb`中。使用代码的更多信息请参见第（？）章。

## 3.1 Stanley Milgram

斯坦利·米拉格（Stanley Milgram）是美国社会心理学家，他进行了两项最著名的社会科学实验，即 Milgram 实验，研究人们对权威的服从（<http://en.wikipedia.org/wiki/Milgram_experiment>）和小世界实验，研究了社交网络的结构（<http://en.wikipedia.org/wiki/Small_world_phenomenon>）。

在小世界实验中，Milgram 向堪萨斯州威奇托（Wichita, Kansas）的几个随机选择的人发送了包裹，带有一个指示，要求他们向马萨诸塞州沙龙（Sharon, Massachusetts）的目标人员发送一封附带的信（在我长大的地方，波士顿附近），目标人员通过名字和职业确定。受访者被告知，只有当他亲自认识目标人员时，才可以将该信直接邮寄给目标；否则他们按照指示，将信和同一个指示发送给他们认为的，更有可能认识目标人员的亲戚或朋友。

许多信件从来没有发出过，但是对于发出的信件，平均路径长度（信件转发次数）的大约为 6。这个结果用于确认以前的观察（和猜测），社交网络中任何两个人之间的通常距离是“六度分隔”。

这个结论令人惊讶，因为大多数人都希望社交网络本地化 - 人们往往会靠近他们的朋友 - 而且在一个具有本地连接的图中，路径长度往往会与地理距离成比例增加。例如，我的大多数朋友都住在附近，所以我猜想社交网络中节点之间的平均距离是大约 50 英里。威奇托距离波士顿约有 1600 英里，所以如果 Milgram 的信件穿过了社交网络的典型环节，那么他们应该有 32 跳，而不是 6 跳。

## 3.2 Watts 和 Strogatz

1998年，Duncan Watts 和 Steven Strogatz 在 Nature 杂志上发表了一篇“小世界网络的集体动态”（Collective dynamics of ’small-world’ networks）论文，提出了小世界现象的解释。 你可以从 <http://www.nature.com/nature/journal/v393/n6684/abs/393440a0.html> 下载。

Watts 和 Strogatz 从两种很好理解的开始：随机图和正则图。在随机图中，节点随机连接。在正则图中，每个节点具有相同数量的邻居。他们考虑这些图的两个属性，群聚性和路径长度：

群聚是图表的“集团性”（cliquishness）的度量。在图中，集团是所有节点的子集，它们彼此连接；在一个社交网络中，集团是一群人，彼此都是朋友。Watts 和 Strogatz 定义了一个群聚系数，用于量化两个节点彼此连接，并同时连接到同一个节点的可能性。

路径长度是两个节点之间的平均距离的度量，对应于社交网络中的分离度。

Watts 和 Strogatz 表明，正则图具有高群聚性和长路径长度，而大小相同的随机图通常具有群聚性和短路径长度。所以这些都不是一个很好的社交网络模型，它是高群聚性与短路径长度的组合。

他们的目标是创造一个社交网络的生成模型。生成模型通过为构建或导致现象的过程建模，试图解释现象。Watts 和 Strogatz 提出了用于构建小世界图的过程：

1.  从一个正则图开始，节点为`n`，每个节点连接`k`个邻居。

2.  选择边的子集，并将它们替换为随机的边来“重新布线”。

边的重新布线的概率是参数`p`，它控制图的随机性。当`p = 0`时，该图是正则的；`p = 1`是随机的。

Watts 和 Strogatz 发现，较小的`p`值产生高群聚性的图，如正则图，短路径长度的图，如随机图。

在本章中，我将按以下步骤复制 Watts 和 Strogatz 实验：

+   我们将从构建一个环格（ring lattice）开始，这是一种正则图。
+   然后我们和 Watts 和 Strogatz 一样重新布线。
+   我们将编写一个函数来测量群聚度，并使用 NetworkX 函数来计算路径长度。
+   然后，我们为范围内的`p`值计算群聚度和路径长度。
+   最后，我将介绍一种用于计算最短路径的高效算法，Dijkstra 算法。

## 3.3 环格

![](img/3-1.jpg)

> 图 3.1 `n=10`，`k=4`的环格

正则图是每个节点具有相同数量的邻居的图；邻居的数量也称为节点的度。
环格是一种正则图，Watts 和 Strogatz 将其用作模型的基础。 在具有`n`个节点的环格中，节点可以排列成圆形，每个节点连接`k`个最近邻居。

例如，`n = 3`和`k = 2`的环形网格将拥有以下边：`(0, 1), (1, 2), (2, 0)`。 请注意，边从编号最高的节点“绕回”0。

更一般地，我们可以像这样枚举边：

```py

def adjacent_edges(nodes, halfk):
    n = len(nodes)
    for i, u in enumerate(nodes):
        for j in range(i+1, i+halfk+1):
            v = nodes[j % n]
            yield u, v
```

`adjacent_edges`接受节点列表和参数`halfk`，它是`k`的一半。它是一个生成器函数，一次产生一个边。它使用模运算符`%`，从编号最高的节点绕回最低的节点。

我们可以这样测试：

```py

>>> nodes = range(3)
>>> for edge in adjacent_edges(nodes, 1):
...     print(edge)
(0, 1)
(1, 2)
(2, 0)
```

现在我们可以使用`adjacent_edges`来生成环格。

```py

def make_ring_lattice(n, k):
    G = nx.Graph()
    nodes = range(n)
    G.add_nodes_from(nodes)
    G.add_edges_from(adjacent_edges(nodes, k//2))
    return G
```

注意，`make_ring_lattice`使用地板除计算`halfk`，所以如果`k`是奇数，它将向下取整并产生具有度`k-1`的环格。这可能不是我们想要的，但现在还不错。

我们可以像这样测试函数：

```py
lattice = make_ring_lattice(10, 4)
```

图（？）展示了结果。

## 3.4 WS 图

![](img/3-2.jpg)

> 图 3.2 WS 图，`n=20`，`k=4`，`p=0`（左边），`p=0.2`（中间），`p=1`（右边）。

为了制作 Watts-Strogatz（WS）图，我们从一个环格开始，并为一些边“重新布线”。 在他们的论文中，Watts 和 Strogatz 以特定顺序考虑边，并用概率`p`重新布置每个边。 如果边被重新布置，则它们使第一个节点保持不变，并随机选择第二个节点。它们不允许自环或多边；也就是说，节点不能拥有到它自身的边，并且两个节点之间不能拥有多个边。

这是我的这个过程的实现。

```py

def rewire(G, p):
    nodes = set(G.nodes())
    for edge in G.edges():
        if flip(p):
            u, v = edge
            choices = nodes - {u} - set(G[u])
            new_v = choice(tuple(choices))
            G.remove_edge(u, v)
            G.add_edge(u, new_v)
```

参数`p`是边的重新布线的概率。`for`循环枚举了边，并使用`flip`，它以概率`p`返回`True`，来选择哪些被重新布置。

如果我们重新布置节点`u`到节点`v`的边，我们必须选择一个节点来替换`v`，称为`new_v`。为了计算可能的选择，我们从节点集开始，它是一个集合，并且移除`u`和它的邻居，这避免了自环和多边。

然后我们从选项中选择new_v，将`u`到`v`的现有删除，并从添加一个`u`到`new_v`的新边。

另外，表达式`G[u]`返回一个字典，他的键是包含`u`的邻居。在这种情况下，它比使用`G.neighbors`更快一点。

这个函数不按照 Watts 和 Strogatz 指定的顺序考虑边缘，但它似乎不会影响结果。

图（？）展示了`n = 20`，`k = 4`和范围内`p`值的 WS 图。当`p = 0`时，该图是环格。 当`p = 1`时，它是完全随机的。我们将看到，有趣的事情发生在两者之间。


## 3.5 群聚性

下一步是计算群聚系数，它量化了节点形成集团的趋势。 集团是一组完全连接的节点；也就是说，在集团中的所有节点对之间都存在边。

假设一个特定的节点`u`具有`k`个邻居。如果所有的邻居都相互连接，则会有`k(k-1)/2`个边。 实际存在的这些边的比例是`u`的局部群聚系数，表示为`Cu`。它被称为“系数”，因为它总是在 0 和 1 之间。

如果我们计算所有节点上的`Cu`平均值，我们得到“网络平均群聚系数”，表示为`C`。

这是一个计算它的函数。

```py

def node_clustering(G, u):
    neighbors = G[u]
    k = len(neighbors)
    if k < 2:
        return 0

    total = k * (k-1) / 2
    exist = 0
    for v, w in all_pairs(neighbors):
        if G.has_edge(v, w):
            exist +=1
    return exist / total
```

同样，我使用`G [u]`，它返回一个字典，键是节点的邻居。如果节点的邻居少于两个，则群聚系数未定义，但为简便起见，`node_clustering`返回 0。

否则，我们计算邻居之间的可能的边数量，`total`，然后计算实际存在的边数量。结果是存在的所有边的比例。

我们可以这样测试函数：

```py

>>> lattice = make_ring_lattice(10, 4)
>>> node_clustering(lattice, 1)
0.5
```

在`k=4`的环格中，每个节点的群聚系数是`0.5`（如果你不相信，可以看看图（？））。

现在我们可以像这样计算网络平均群聚系数：

```py

def clustering_coefficient(G):
    cc = np.mean([node_clustering(G, node) for node in G])
    return cc
```

`np.mean` 是个 NumPy 函数，计算列表或数组中元素的均值。

然后我们可以像这样测试：

```py

>>> clustering_coefficient(lattice)
0.5
```

这个图中，所有节点的局部群聚系数是 0.5，所以节点的平均值是 0.5。当然，我们期望这个值和 WS 图不同。

## 3.6 最短路径长度

下一步是计算特征路径长度`L`，它是每对节点之间最短路径的平均长度。 为了计算它，我将从 NetworkX 提供的函数开始，`shortest_path_length`。 我会用它来复制 Watts 和 Strogatz 实验，然后我将解释它的工作原理。

这是一个函数，它接受图并返回最短路径长度列表，每对节点一个。

```py

def path_lengths(G):
    length_map = nx.shortest_path_length(G)
    lengths = [length_map[u][v] for u, v in all_pairs(G)]
    return lengths
```

`nx.shortest_path_length`的返回值是字典的字典。外层字典每个节点`u`到内层字典的映射，内层字典是每个节点`v`到`u->v`的最短路径长度的映射。

使用来自`path_lengths`的长度列表，我们可以像这样计算`L`：

```py

def characteristic_path_length(G):
    return np.mean(path_lengths(G))
```

并且我们可以使用小型的环格来测试它。

```py

>>> lattice = make_ring_lattice(3, 2)
>>> characteristic_path_length(lattice)
1.0
```

这个例子中，所有三个节点都互相连接，所以平均长度为 1。

## 3.7 WS 实验

![](img/3-3.jpg)

> 图 3.3：WS 图的群聚系数`C`和特征路径长度`L`，其中`n=1000, k=10`，`p`是一个范围。

现在我们准备复制 WS 实验，它表明对于一系列`p`值，WS 图具有像正则图像那样的高群聚性，像随机图一样的短路径长度。

我将从`run_one_graph`开始，它接受`n`，`k`和`p`；它生成具有给定参数的 WS图，并计算平均路径长度`mpl`和群聚系数`cc`：

```py

def run_one_graph(n, k, p):
    ws = make_ws_graph(n, k, p)
    mpl = characteristic_path_length(ws)
    cc = clustering_coefficient(ws)
    print(mpl, cc)
    return mpl, cc
```
sssss
Watts 和 Strogatz 用`n = 1000`和`k = 10`进行实验。使用这些参数，`run_one_graph`在我的电脑上需要大约一秒钟；大部分时间用于计算平均路径长度。

现在我们需要为范围内的`p`计算这些值。我将再次使用 NumPy 函数`logspace`来计算`ps`：

```py

ps = np.logspace(-4, 0, 9)
```

对于每个`p`的值，我生成了 3 个随机图，并且我们将结果平均。这里是运行实验的函数：

```py

def run_experiment(ps, n=1000, k=10, iters=3):
    res = {}
    for p in ps:
        print(p)
        res[p] = []
        for _ in range(iters):
            res[p].append(run_one_graph(n, k, p))
    return res
```

结果是个字典，将每个`p`值映射为`(mpl, cc)`偶对的列表。

最后一步就是聚合结果：

```py

L = []
C = []
for p, t in sorted(res.items()):
    mpls, ccs = zip(*t)
    mpl = np.mean(mpls)
    cc = np.mean(ccs)
    L.append(mpl)
    C.append(cc)
```

每次循环时，我们取得一个`p`值和一个`(mpl, cc)`偶对的列表。 我们使用`zip`来提取两个列表，`mpls`和`ccs`，然后计算它们的均值并将它们添加到`L`和`C`，这是路径长度和群聚系数的列表。

为了在相同的轴上绘制`L`和`C`，我们通过除以第一个元素，将它们标准化：

```py

L = np.array(L) / L[0]
C = np.array(C) / C[0]
```


图（？）展示了结果。 随着`p`的增加，平均路径长度迅速下降，因为即使少量随机重新布线的边，也提供了图区域之间的捷径，它们在格中相距很远。另一方面，删除局部链接降低了群聚系数，但是要慢得多。

因此，存在较宽范围的`p`，其中 WS 图具有小世界图的性质，高群聚度和短路径长度。

这就是为什么 Watts 和 Strogatz 提出了 WS 图，作为展示小世界现象的，现实世界网络的模型。

## 3.8 能有什么解释？

如果你问我，为什么行星轨道是椭圆形的，我最开始会为一个行星和一个恒星建模；我将在 <http://en.wikipedia.org/wiki/Newton's_law_of_universal_gravitation> 上查找万有引力定律，并用它为行星的运动写出一个微分方程。之后我会扩展轨道方程式，或者更有可能在 <http://en.wikipedia.org/wiki/Orbit_equation> 上查找。通过一个小的代数运算，我可以得出产生椭圆轨道的条件。之后我会证明我们看做行星的物体满足这些条件。

人们，或至少是科学家，一般对这种解释感到满意。它有吸引力的原因之一是，模型中的假设和近似值似乎是合理的。行星和恒星不是真正的质点，但它们之间的距离是如此之大，以至于它们的实际尺寸可以忽略不计。同一太阳系中的行星可以影响彼此的轨道，但效果通常较小。而且我们忽视相对论的影响，再次假定它们很小。

这也因为它是基于方程式的。我们可以用闭式表达轨道方程，这意味着我们可以有效地计算轨道。这也意味着我们可以得出轨道速度，轨道周期和其他数量的一般表达式。

最后，我认为这是因为它具有数学证明的形式。它从一组公理开始，通过逻辑和分析得出结果。但重要的是要记住，证明属于模型，而不是现实世界。也就是说，我们可以证明，行星的理想模型产生一个椭圆轨道，但是我们不能证明这个模型与实际的行星有关（实际上它不是）。

+   这些模型可以做什么工作：它们是预测性的还是说明性的，还是都有？
+   这些模型的解释，是否比基于更传统模型的解释更不满意？为什么？
+   我们应该如何刻画这些和更传统的模型之间的差异？他们在种类还是程度上不同？

在这本书中，我将提供我对这些问题的回答，但它们是暂时性的，有时是投机性的。我鼓励你怀疑地思考他们，并得出你自己的结论。

## 3.9 广度优先搜索

当我们计算最短路径时，我们使用了 NetworkX 提供的一个函数，但是我没有解释它是如何工作的。为此，我将从广度优先搜索开始，这是用于计算最短路径的 Dijkstra 算法的基础。

在第（？）节，我提出了`reachable_nodes`，它寻找从给定的起始节点可以到达的所有节点：

```py

def reachable_nodes(G, start):
    seen = set()
    stack = [start]
    while stack:
        node = stack.pop()
        if node not in seen:
            seen.add(node)
            stack.extend(G.neighbors(node))
    return seen
```

我当时没有这么说，但它执行深度优先搜索（DFS）。现在我们将修改它来执行广度优先搜索（BFS）。

为了了解区别，想象一下你正在探索一座城堡。你最开始在一个房间里，带有三个门，标记为 A，B 和 C 。你打开门 C 并发现另一个房间，它的门被标记为 D ，E 和 F。

下面你打开哪个门呢？如果你打算冒险，你可能想更深入城堡，选择 D，E 或 F。这是一个深度优先搜索。

但是，如果你想更系统化，你可以在 D，E 和 F 之前回去探索 A 和 B，这将是一个广度优先搜索。

在`reachable_nodes`中，我们使用`list.pop`选择下一个节点来“探索”。默认情况下，`pop`返回列表的最后一个元素，这是我们添加的最后一个元素。在这个例子中，这是门 F。

如果我们要执行 BFS，最简单的解决方案是将第一个元素从栈中弹出：

```py
node = stack.pop(0)
```

这有效，但速度很慢。在 Python 中，弹出列表的最后一个元素需要常数时间，但是弹出第一个元素线性于列表的长度。在最坏的情况下，就是堆栈的长度`O(n)`，这使得 BFS 的`O(nm)`的实现比`O(n + m)`差得多。

我们可以用双向队列（也称为`deque`）来解决这个问题。`deque`的一个重要特征就是，你可以在开头和末尾添加和删除元素。要了解如何实现，请参阅 <https://en.wikipedia.org/wiki/Double-ended_queue>。

Python 在`collections`模块中提供了`deque`，所以我们可以像这样导入它：

```py

from collections import deque
```

我们可以使用它来编写高效的 BFS：

```py

def reachable_nodes_bfs(G, start):
    seen = set()
    queue = deque([start])
    while queue:
        node = queue.popleft()
        if node not in seen:
            seen.add(node)
            queue.extend(G.neighbors(node))
    return seen
```

差异在于：

+   我用名为`queue`的`deque`替换了名为`stack`的列表。
+   我用`popleft`替换`pop`，它删除并返回队列的最左边的元素，这是第一个添加的元素。

这个版本恢复为`O(n + m)`。现在我们做好了寻找最短路径的准备。
