# 四、无标度网络

在本章中，我们将处理来自在线社交网络的数据，并使用 WS 图对其进行建模。WS 模型像数据一样，具有小世界网络的特点，但是与数据不同，它的节点到节点的邻居数目变化很小。

这种差异是 Barabási 和 Albert 开发的网络模型的动机。BA 模型捕捉到邻居数量的观察到的变化，它具有小的世界属性之一，短路径长度，但它没有一个小世界网络的高聚类。

本章最后讨论了 WS 和 BA 图，作为小世界网络的解释模型。

本章的代码位于本书的仓库中的`chap04.ipynb`中。使用代码的更多信息，请参见第（？）章。

## 4.1 社交网络数据

WS 图的目的是，模拟自然科学和社会科学中的网络。Watts 和 Strogatz 在他们最初的论文中，查看了电影演员的网络（如果他们出现在同一部电影中，就是连接的）。美国西部的电网；和 C. elegans 线虫脑中的神经元网络 。他们发现，所有这些网络都具有小世界图的高群聚性和短路径长度特征。

在本节中，我们将使用不同的数据集，Facebook 用户及其朋友的数据集，来进行相同的分析。如果你对 Facebook 不熟悉，那么彼此连接的用户被称为“朋友”，而不管他们在现实世界中的关系的性质如何。

我将使用来自斯坦福网络分析项目（SNAP）的数据，该项目分享了来自在线社交网络和其他来源的大型数据集。具体来说，我将使用他们的 Facebook 数据集 1，其中包括 4039 个用户和 88,234 个朋友关系。该数据集位于本书的仓库中，但也可以从 [SNAP 网站](https://snap.stanford.edu/data/egonets-Facebook.html)上获取。

数据文件为每条边包含一行，用户由 0 到 4038 之间的整数标识。下面是读取文件的代码：

```py

def read_graph(filename):
    G = nx.Graph()
    array = np.loadtxt(filename, dtype=int)
    G.add_edges_from(array)
    return G
```

NumPy 提供了函数`loadtext`，它读取给定的文件，并以 NumPy 数组的形式返回内容。参数`dtype`指定数组元素的类型。

然后我们可以使用`add_edges_from`迭代数组的行，并创建边。结果如下：

```py
>>> fb = read_graph('facebook_combined.txt.gz')
>>> n = len(fb)
>>> m = len(fb.edges())
>>> n, m
(4039, 88234)
```

节点和边的数量与数据集的文档一致。

现在我们可以检查这个数据集是否具有小世界图的特征：高群聚性和短路径长度。

第（？）节中，我们编写了一个函数，来计算网络平均群聚系数。NetworkX 提供了一个叫做的函数`average_clustering`，它可以更快地完成相同的工作。

但是对于更大的图，它们都太慢，需要与`nk^2`成正比的时间，其中`n`是节点数，`k`是每个节点的邻居数。

幸运的是，`NetworkX`提供了一个通过随机抽样来估计群聚系数的函数。你可以像这样调用它：

```py

    from networkx.algorithms.approximation import average_clustering
    average_clustering(G, trials=1000)
```

下面函数对路径长度做了类似的事情：

```py

def random_path_lengths(G, nodes=None, trials=1000):
    if nodes is None:
        nodes = G.nodes()
    else:
        nodes = list(nodes)

    pairs = np.random.choice(nodes, (trials, 2))
    lengths = [nx.shortest_path_length(G, *pair)
               for pair in pairs]
    return lengths
```

`G`是一个图，`nodes`是节点列表，我们应该从中抽样，`trials`是要抽样的随机路径的数量。如果`nodes`是`None`，我们从整个图表中进行抽样。

`pairs`是随机选择的节点的 NumPy 数组，对于每个采样有一行两列。

列表推导式枚举数组中的行，并计算每对节点之间的最短距离。结果是路径长度的列表。

`estimate_path_length`生成一个随机路径长度列表，并返回它们的平均值：

```py

def estimate_path_length(G, nodes=None, trials=1000):
    return np.mean(random_path_lengths(G, nodes, trials))
```

我会使用`average_clustering `来计算`C`：

```py
C = average_clustering(fb)
```

并使用`estimate_path_lengths`来计算`L`：

```py
L = estimate_path_lengths(fb)
```

群聚系数约为`0.61`，这是较高的，正如我们所期望的那样，如果这个网络具有小世界特性。

平均路径为`3.7`，在 4000 多个用户的网络中相当短。毕竟这是一个小世界。

现在让我们看看是否可以构建一个 WS 图，与此网络具有相同特征。

## 4.2 WS 模型

在 Facebook 数据集中，每个节点的平均边数约为 22。由于每条边都连接到两个节点，平均度是每个节点边数的两倍：

```py

>>> k = int(round(2*m/n))
>>> k
44
```

我们可以用`n=4039`和`k=44`创建一个 WS 图。`p=0`时，我们会得到一个环格。

```py

lattice = nx.watts_strogatz_graph(n, k, 0)
```

在这个图中，群聚较高：`C`是 0.73，而在数据集中是 0.61。但是`L`为 46，远远高于数据集！

使用`p=1`我们得到一个随机图：

```py
random_graph = nx.watts_strogatz_graph(n, k, 1)
```

在随机图中，`L`是 2.6，甚至比数据集（3.7）短，但`C`只有 0.011，所以这是不好的。

通过反复试验，我们发现，当`p=0.05`时，我们得到一个高群聚和短路径长度的 WS 图：

```py

ws = nx.watts_strogatz_graph(n, k, 0.05, seed=15)
```

在这个图中`C`是`0.63`，比数据集高一点，`L`是 3.2，比数据集低一点。所以这个图很好地模拟了数据集的小世界特征。

到现在为止还不错。

## 4.3 度

![](img/4-1.png)

> 图 4.1：Facebook 数据集和 WS 模型中的度的 PMF。

回想一下，节点的度是它连接到的邻居的数量。如果 WS 图是 Facebook 网络的一个很好的模型，它应该具有相同的总（或平均）度，理想情况下不同节点的度数相同。

这个函数返回图中的度的列表，每个节点对应一项：

```py

def degrees(G):
    return [G.degree(u) for u in G]
```

数据集中的平均度是 43.7；WS 模型中的平均度是 44。到目前为止还不错。

但是，WS 模型中的度的标准差为 1.5；数据中的标准差是 52.4。有点糟。

这里发生了什么？为了更好地查看，我们必须看看度的 分布，而不仅仅是均值和标准差。

我将用一个 Pmf 对象来表示度的分布，它在`thinkstats2`模块中定义。Pmf 代表“概率质量函数”；如果你不熟悉这个概念，你可以阅读 Think Stats 第二版的第三章，网址是 <http://greenteapress.com/thinkstats2/html/thinkstats2004.html>。

简而言之，Pmf 是值到概率的映射。Pmf 是每个可能的度`d`，到度为`d`的节点比例的映射。

作为一个例子，我将构建一个图，拥有节点`1, 2, 3`，连接到中心节点`0`：

```py
G = nx.Graph()
G.add_edge(1, 0)
G.add_edge(2, 0)
G.add_edge(3, 0)
nx.draw(G)
```

这里是图中的度的列表：

```py

>>> degrees(G)
[3, 1, 1, 1]
```

节点`0`度为 3，其它度为 1。现在我可以生成一个 Pmf，它表示这个度的分布：

```py
>>> from thinkstats2 import Pmf
>>> Pmf(degrees(G))
Pmf({1: 0.75, 3: 0.25})
```

产生的`Pmf`是一个对象，将每个度映射到一个比例或概率。在这个例子中，75％的节点度为 1，25％度为 3。

现在我们生成一个`Pmf`，包含来自数据集的节点的度，并计算均值和标准差：

```py

>>> pmf_ws = Pmf(degrees(ws))
>>> pmf_ws.mean(), pmf_ws.std()
(44.000, 1.465)
```

我们可以使用`thinkplot`模块来绘制结果：

```py
thinkplot.Pdf(pmf_fb, label='Facebook')
thinkplot.Pdf(pmf_ws, label='WS graph')
```

图（？）显示了这两个分布。他们是非常不同的。

在 WS 模型中，大多数用户有大约 44 个朋友；最小值是 38，最大值是 50。这个变化不大。在数据集中，有很多用户只有 1 或 2 个朋友，但有一个人有 1000 多个！

像这样的分布，有许多小的值和一些非常大的值，被称为重尾。

## 4.4 重尾分布

![](img/4-2.png)

> 图 4.2：Facebook 数据集和 WS 模型中的度的 PMF，在双对数刻度下。

在复杂性科学的许多领域中，重尾分布是一个常见特征，它们将成为本书的一个反复出现的主题。

我们可以在双对数轴绘制它，来获得重尾分布的更清晰的图像，就像上面那副图那样。这种转换突显了分布的尾巴；也就是较大值的概率。

在这种转换下，数据大致在一条直线上，这表明分布的最大值与概率之间存在“幂律”关系。在数学上，

```
PMF(k) ~ k^(−α)
```

其中`PMF(k)`是度为`k`的节点的比例，`α`是一个参数，符号`~`表示当`k`增加时，PMF 渐近于`k^(−α)`。

如果我们把对两边取对数，我们得到：

```

logPMF(k) ~ −α logk 
```

因此，如果一个分布遵循幂律，并且我们在双对数刻度上绘制`PMF(k)`与`k`的关系，那么我们预计至少对于`k`的较大值，将有一条斜率为`-α`的直线。

所有的幂律分布都是重尾的，但是还有其他重尾分布不符合幂律。我们将很快看到更多的例子。

但首先，我们有一个问题：WS 模型拥有高群聚性和短路径长度，我们在数据中也看到了，但度的分布根本不像数据。这种差异就启发了我们下一个主题，Barabási-Albert 模型。

